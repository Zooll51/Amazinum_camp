{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "## Home Task \n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Topic Modeling \n",
    "\n",
    "</font>\n",
    "\n",
    "[voted-kaggle-dataset](https://www.kaggle.com/canggih/voted-kaggle-dataset/version/2#voted-kaggle-dataset.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords \n",
    "fn= 'Archive/voted-kaggle-dataset.csv'\n",
    "df = pd.read_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of texts= 2,150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'These files contain complete loan data for all loans issued through the 2007-2015, including the current loan status (Current, Late, Fully Paid, etc.) and latest payment information. The file containing loan data through the \"present\" contains complete loan data for all loans issued through the previous completed calendar quarter. Additional features include credit scores, number of finance inquiries, address including zip codes, and state, and collections among others. The file is a matrix of about 890 thousand observations and 75 variables. A data dictionary is provided in a separate file. k'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('len of texts= {:,}'.format(len(df)))\n",
    "index = 10 \n",
    "df.loc[index, 'Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    The datasets contains transactions made by cre...\n",
       "1    The ultimate Soccer database for data analysis...\n",
       "2    Background\\nWhat can we say about the success ...\n",
       "3    Context\\nInformation on more than 170,000 Terr...\n",
       "4    Context\\nBitcoin is the longest running and mo...\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions = df[df['Description'].notnull()]['Description']\n",
    "descriptions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(min_df=20,\n",
       "                stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;, &#x27;again&#x27;, &#x27;against&#x27;,\n",
       "                            &#x27;ain&#x27;, &#x27;all&#x27;, &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                            &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;, &#x27;because&#x27;,\n",
       "                            &#x27;been&#x27;, &#x27;before&#x27;, &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                            &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;, &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...},\n",
       "                token_pattern=&#x27;\\\\b\\\\w{3,}\\\\b&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(min_df=20,\n",
       "                stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;, &#x27;again&#x27;, &#x27;against&#x27;,\n",
       "                            &#x27;ain&#x27;, &#x27;all&#x27;, &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                            &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;, &#x27;because&#x27;,\n",
       "                            &#x27;been&#x27;, &#x27;before&#x27;, &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                            &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;, &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...},\n",
       "                token_pattern=&#x27;\\\\b\\\\w{3,}\\\\b&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(min_df=20,\n",
       "                stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                            'aren', \"aren't\", 'as', 'at', 'be', 'because',\n",
       "                            'been', 'before', 'being', 'below', 'between',\n",
       "                            'both', 'but', 'by', 'can', 'couldn', \"couldn't\", ...},\n",
       "                token_pattern='\\\\b\\\\w{3,}\\\\b')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english')).union({'data', 'dataset', 'model'})\n",
    "three_words_pattern = r\"\\b\\w{3,}\\b\"\n",
    "vectorizer = CountVectorizer(\n",
    "    min_df=20, \n",
    "    stop_words=stop_words,\n",
    "    token_pattern=three_words_pattern) \n",
    "vectorizer.fit(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of features = 1,872\n",
      "\n",
      "['000', '100', '1000', '1995', '1st', '200', '2000', '2001', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2nd', '300', '400', '500', '600', 'ability', 'able', 'abs', 'abstract', 'academic', 'access', 'accessed', 'accessible', 'accompanying', 'according', 'account']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dima\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print ('len of features = {:,}\\n'.format(len(vectorizer.get_feature_names())))\n",
    "print (vectorizer.get_feature_names()[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions_data_vectorized= vectorizer.transform(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = gensim.matutils.Sparse2Corpus(descriptions_data_vectorized, documents_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map = dict((v, k) for k, v in vectorizer.vocabulary_.items()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.030*\"description\" + 0.030*\"yet\" + 0.014*\"trained\" + 0.010*\"time\" + 0.009*\"pre\" + 0.009*\"features\" + 0.007*\"context\" + 0.007*\"content\" + 0.007*\"using\" + 0.007*\"use\" + 0.006*\"team\" + 0.006*\"acknowledgements\" + 0.006*\"set\" + 0.006*\"contains\" + 0.006*\"number\" + 0.006*\"available\" + 0.005*\"player\" + 0.005*\"information\" + 0.005*\"game\" + 0.005*\"inspiration\"'),\n",
       " (1,\n",
       "  '0.008*\"back\" + 0.008*\"context\" + 0.007*\"activity\" + 0.007*\"music\" + 0.007*\"using\" + 0.007*\"research\" + 0.007*\"content\" + 0.007*\"based\" + 0.006*\"features\" + 0.006*\"speech\" + 0.006*\"lower\" + 0.006*\"use\" + 0.006*\"acknowledgements\" + 0.006*\"information\" + 0.006*\"class\" + 0.005*\"new\" + 0.005*\"time\" + 0.005*\"may\" + 0.005*\"collected\" + 0.005*\"contains\"'),\n",
       " (2,\n",
       "  '0.178*\"university\" + 0.021*\"state\" + 0.008*\"new\" + 0.007*\"content\" + 0.007*\"institute\" + 0.007*\"information\" + 0.007*\"context\" + 0.006*\"california\" + 0.006*\"acknowledgements\" + 0.006*\"college\" + 0.006*\"contains\" + 0.006*\"city\" + 0.005*\"one\" + 0.005*\"cell\" + 0.005*\"instances\" + 0.005*\"inspiration\" + 0.005*\"time\" + 0.005*\"technology\" + 0.005*\"community\" + 0.005*\"images\"'),\n",
       " (3,\n",
       "  '0.013*\"content\" + 0.012*\"acknowledgements\" + 0.011*\"context\" + 0.011*\"time\" + 0.011*\"inspiration\" + 0.009*\"price\" + 0.008*\"https\" + 0.007*\"use\" + 0.006*\"many\" + 0.006*\"www\" + 0.006*\"date\" + 0.006*\"com\" + 0.006*\"number\" + 0.005*\"business\" + 0.005*\"world\" + 0.005*\"set\" + 0.004*\"others\" + 0.004*\"based\" + 0.004*\"csv\" + 0.004*\"reviews\"'),\n",
       " (4,\n",
       "  '0.022*\"content\" + 0.017*\"context\" + 0.012*\"inspiration\" + 0.012*\"acknowledgements\" + 0.010*\"contains\" + 0.009*\"information\" + 0.009*\"com\" + 0.008*\"2017\" + 0.007*\"set\" + 0.007*\"used\" + 0.007*\"times\" + 0.006*\"url\" + 0.006*\"collected\" + 0.006*\"different\" + 0.006*\"kaggle\" + 0.006*\"many\" + 0.005*\"one\" + 0.005*\"weather\" + 0.005*\"games\" + 0.005*\"day\"'),\n",
       " (5,\n",
       "  '0.096*\"university\" + 0.038*\"state\" + 0.032*\"college\" + 0.011*\"california\" + 0.008*\"census\" + 0.008*\"population\" + 0.007*\"1995\" + 0.007*\"service\" + 0.006*\"context\" + 0.006*\"name\" + 0.006*\"content\" + 0.005*\"year\" + 0.005*\"contains\" + 0.005*\"district\" + 0.005*\"information\" + 0.005*\"variables\" + 0.005*\"new\" + 0.005*\"use\" + 0.004*\"acknowledgements\" + 0.004*\"per\"'),\n",
       " (6,\n",
       "  '0.031*\"csv\" + 0.012*\"number\" + 0.009*\"company\" + 0.009*\"context\" + 0.009*\"content\" + 0.008*\"inspiration\" + 0.008*\"row\" + 0.006*\"total\" + 0.006*\"name\" + 0.006*\"government\" + 0.006*\"acknowledgements\" + 0.006*\"2017\" + 0.006*\"new\" + 0.006*\"contains\" + 0.005*\"files\" + 0.005*\"information\" + 0.005*\"date\" + 0.005*\"year\" + 0.005*\"file\" + 0.005*\"code\"'),\n",
       " (7,\n",
       "  '0.010*\"com\" + 0.009*\"context\" + 0.009*\"content\" + 0.009*\"information\" + 0.009*\"used\" + 0.009*\"tweet\" + 0.008*\"column\" + 0.008*\"acknowledgements\" + 0.008*\"inspiration\" + 0.008*\"datasets\" + 0.007*\"contains\" + 0.007*\"find\" + 0.007*\"https\" + 0.007*\"time\" + 0.006*\"columns\" + 0.006*\"www\" + 0.006*\"following\" + 0.005*\"many\" + 0.005*\"per\" + 0.005*\"tweets\"'),\n",
       " (8,\n",
       "  '0.013*\"number\" + 0.011*\"contains\" + 0.010*\"instances\" + 0.009*\"time\" + 0.008*\"used\" + 0.008*\"cell\" + 0.008*\"different\" + 0.007*\"results\" + 0.006*\"one\" + 0.006*\"context\" + 0.006*\"content\" + 0.006*\"learning\" + 0.005*\"like\" + 0.005*\"two\" + 0.005*\"game\" + 0.005*\"models\" + 0.005*\"position\" + 0.005*\"information\" + 0.005*\"set\" + 0.004*\"whether\"'),\n",
       " (9,\n",
       "  '0.013*\"content\" + 0.010*\"news\" + 0.010*\"information\" + 0.009*\"age\" + 0.009*\"2005\" + 0.009*\"education\" + 0.009*\"used\" + 0.009*\"contains\" + 0.008*\"context\" + 0.008*\"acknowledgements\" + 0.008*\"gov\" + 0.008*\"educational\" + 0.007*\"file\" + 0.007*\"number\" + 0.006*\"set\" + 0.006*\"words\" + 0.006*\"time\" + 0.005*\"https\" + 0.005*\"space\" + 0.005*\"sales\"')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=10, id2word=id_map)#, passes=25)\n",
    "ldamodel.print_topics(num_topics=10,num_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_names= [\"Social Media\",\n",
    "    \"Education\",\n",
    "    \"News and Sports\",\n",
    "    \"Web Resources\",\n",
    "    \"Demographics\",\n",
    "    \"Biology\",\n",
    "    \"Technology\",\n",
    "    \"Research\",\n",
    "    \"Data Analysis\",\n",
    "    \"Machine Learning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background\n",
      "What can we say about the success of a movie before it is released? Are there certain companies (Pixar?) that have found a consistent formula? Given that major films costing over $100 million to produce can still flop, this question is more important than ever to the industry. Film aficionados might have different interests. Can we predict which films will be highly rated, whether or not they are a commercial success?\n",
      "This is a great place to start digging in to those questions, with data on the plot, cast, crew, budget, and revenues of several thousand films.\n",
      "Data Source Transfer Summary\n",
      "We (Kaggle) have removed the original version of this dataset per a DMCA takedown request from IMDB. In order to minimize the impact, we're replacing it with a similar set of films and data fields from The Movie Database (TMDb) in accordance with their terms of use. The bad news is that kernels built on the old dataset will most likely no longer work.\n",
      "The good news is that:\n",
      "You can port your existing kernels over with a bit of editing. This kernel offers functions and examples for doing so. You can also find a general introduction to the new format here.\n",
      "The new dataset contains full credits for both the cast and the crew, rather than just the first three actors.\n",
      "Actor and actresses are now listed in the order they appear in the credits. It's unclear what ordering the original dataset used; for the movies I spot checked it didn't line up with either the credits order or IMDB's stars order.\n",
      "The revenues appear to be more current. For example, IMDB's figures for Avatar seem to be from 2010 and understate the film's global revenues by over $2 billion.\n",
      "Some of the movies that we weren't able to port over (a couple of hundred) were just bad entries. For example, this IMDB entry has basically no accurate information at all. It lists Star Wars Episode VII as a documentary.\n",
      "Data Source Transfer Details\n",
      "Several of the new columns contain json. You can save a bit of time by porting the load data functions from this kernel.\n",
      "Even in simple fields like runtime may not be consistent across versions. For example, previous dataset shows the duration for Avatar's extended cut while TMDB shows the time for the original version.\n",
      "There's now a separate file containing the full credits for both the cast and crew.\n",
      "All fields are filled out by users so don't expect them to agree on keywords, genres, ratings, or the like.\n",
      "Your existing kernels will continue to render normally until they are re-run.\n",
      "If you are curious about how this dataset was prepared, the code to access TMDb's API is posted here.\n",
      "New columns:\n",
      "homepage\n",
      "id\n",
      "original_title\n",
      "overview\n",
      "popularity\n",
      "production_companies\n",
      "production_countries\n",
      "release_date\n",
      "spoken_languages\n",
      "status\n",
      "tagline\n",
      "vote_average\n",
      "Lost columns:\n",
      "actor_1_facebook_likes\n",
      "actor_2_facebook_likes\n",
      "actor_3_facebook_likes\n",
      "aspect_ratio\n",
      "cast_total_facebook_likes\n",
      "color\n",
      "content_rating\n",
      "director_facebook_likes\n",
      "facenumber_in_poster\n",
      "movie_facebook_likes\n",
      "movie_imdb_link\n",
      "num_critic_for_reviews\n",
      "num_user_for_reviews\n",
      "Open Questions About the Data\n",
      "There are some things we haven't had a chance to confirm about the new dataset. If you have any insights, please let us know in the forums!\n",
      "Are the budgets and revenues all in US dollars? Do they consistently show the global revenues?\n",
      "This dataset hasn't yet gone through a data quality analysis. Can you find any obvious corrections? For example, in the IMDb version it was necessary to treat values of zero in the budget field as missing. Similar findings would be very helpful to your fellow Kagglers! (It's probably a good idea to keep treating zeros as missing, with the caveat that missing budgets much more likely to have been from small budget films in the first place).\n",
      "Inspiration\n",
      "Can you categorize the films by type, such as animated or not? We don't have explicit labels for this, but it should be possible to build them from the crew's job titles.\n",
      "How sharp is the divide between major film studios and the independents? Do those two groups fall naturally out of a clustering analysis or is something more complicated going on?\n",
      "Acknowledgements\n",
      "This dataset was generated from The Movie Database API. This product uses the TMDb API but is not endorsed or certified by TMDb. Their API also provides access to data on many additional movies, actors and actresses, crew members, and TV shows. You can try it for yourself here.\n",
      "[[(0, 0.08119295), (3, 0.06739897), (6, 0.17227338), (7, 0.5081141), (8, 0.1689095)]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Web Resources'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc = [df.loc[2, 'Description']]\n",
    "print(new_doc[0])\n",
    "\n",
    "doc_vectorized= vectorizer.transform(new_doc) # input param is list\n",
    "new_doc_corpus = gensim.matutils.Sparse2Corpus(doc_vectorized, documents_columns=False)\n",
    "doc_topics = ldamodel.get_document_topics(new_doc_corpus)\n",
    "print(list(doc_topics))\n",
    "\n",
    "def elicit_topic_name(doc_topics):    \n",
    "    return topics_names[np.squeeze(np.array(doc_topics))[:,1].argmax()]\n",
    "elicit_topic_name(doc_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
